{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87bf9591-b1e9-4c42-8225-0416f2006654",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "200a18c9-db96-4072-8b85-6acad84ffd7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "\n",
    "spark.sql(\"USE CATALOG `fomacao_microsoft_power_bi_profisional`\")\n",
    "spark.sql(\"USE `pessoas`\")\n",
    "\n",
    "batch_id = str(uuid.uuid4())\n",
    "\n",
    "landing_path = \"/Volumes/fomacao_microsoft_power_bi_profisional/pessoas/landing/processado/PESSOAS.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff47b079-9f72-41de-a749-a6f85e5ae270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_raw = (spark.read\n",
    "               .option(\"header\", True)\n",
    "               .option(\"encoding\", \"UTF-8\")\n",
    "               .option(\"inferSchema\", True)\n",
    "               .option(\"multiline\", True)\n",
    "               .option(\"mode\", \"PERMISSIVE\")\n",
    "               .csv(landing_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca08b84b-a9b9-4899-ab4b-c460893e6bfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cols_for_hash = [c for c in df_raw.columns]\n",
    "\n",
    "df_bronze = (df_raw.withColumn(\"_ingest_ts_utc\", F.current_timestamp())\n",
    "                   .withColumn(\"_ingest_date\", F.to_date(F.col(\"_ingest_ts_utc\")))\n",
    "                   .withColumn(\"_source_path\", F.col(\"_metadata.file_path\"))\n",
    "                   .withColumn(\"_source_file\", F.regexp_extract(F.col(\"_source_path\"), r\"([^/]+)$\", 1))\n",
    "                   .withColumn(\"_batch_id\", F.lit(batch_id))\n",
    "                   .withColumn(\"_row_hash\",\n",
    "                               F.sha2(F.concat_ws(\"ยง\", *[F.coalesce(F.col(c).cast(\"string\"), F.lit(\"\")) for c in cols_for_hash]), 256)\n",
    "                               )\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ab425be-428b-4b1b-8140-255ed9438873",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tbl = \"bronze_pessoas\"\n",
    "\n",
    "if not spark.catalog.tableExists(tbl):\n",
    "    (df_bronze.write\n",
    "              .format(\"delta\")\n",
    "              .mode(\"overwrite\")\n",
    "              .option(\"mergeSchema\", \"true\")\n",
    "              .partitionBy(\"_ingest_date\")\n",
    "              .saveAsTable(tbl))\n",
    "else:\n",
    "    (df_bronze.write\n",
    "              .format(\"delta\")\n",
    "              .mode(\"append\")\n",
    "              .option(\"mergeSchema\", \"true\")\n",
    "              .saveAsTable(tbl))\n",
    "    \n",
    "print(f\"Bronze count: {spark.table(tbl).count()}\")\n",
    "spark.table(tbl).limit(5).display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "002-Bronze_Ingestao",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
